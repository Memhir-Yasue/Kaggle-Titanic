{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# Any results you write to the current directory are saved as output.\n\nimport os\nprint(os.listdir(\"../input\"))\n# Read the training data\ntrain = pd.read_csv('../input/train.csv')\n# Read the testing data\ntest = pd.read_csv('../input/test.csv')\nprint(train.head())\n\n\n# Display meta-data for training and testing data\ntrain.info()\nprint(\"_\"*50+\"\\n\") # Print line\ntest.info()\nprint(\"\\n\"*5)\n# Display columns (from training) to select what to use for prediction\nprint(train.columns)\n\n# print(train.Age.median())\n\n# Repalce NAN values with median age\ntrain.Age = train.Age.fillna(train.Age.median())\n# Replace NAN with S\ntrain.Embarked.fillna(\"S\", inplace=True)\n# Replace string objects with ints\ntrain.Sex = train.Sex.map({\"male\": 0, \"female\":1})\ntrain.Embarked = train.Embarked.map({\"S\":0,\"C\":1,\"Q\":2}) \n\n\n\n\n\n# What will be predicted\ntrain_y = train.Survived\n\n\n# What will be used to make prediction\npredictor_column = ['Sex','Pclass','Age','Embarked','Fare','Parch']\n\n# Create training predictor data\ntrain_X = train[predictor_column]\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n# x_train = sc.fit_transform(x_train)\n# x_test = sc.transform(x_test)\n\ntrain_X = sc.fit_transform(train_X)\n\n\n# my_model = RandomForestRegressor(max_depth=5, n_estimators=30)\nmy_model = RandomForestRegressor(max_depth = 6, n_estimators = 300)\n\n# Fiting the model\nmy_model.fit(train_X, train_y)\n#*************\n#\t\n#\tTest data \n#\n#*************\n\n# Replace NAN value with median age\ntest.Age = test.Age.fillna(test.Age.median())\ntest.Fare = test.Fare.fillna(test.Fare.median())\ntest.Embarked.fillna(\"S\", inplace=True)\n\ntest.Sex = test.Sex.map({\"male\": 0, \"female\":1})\ntest.Embarked = test.Embarked.map({\"S\":0,\"C\":1,\"Q\":2}) \n\ntest_X = test[predictor_column]\ntest_X = sc.fit_transform(test_X)\n\npredicted_survival = my_model.predict(test_X)\npredicted_survival_clean = []\n\nprint(predicted_survival)\n\n\nfor item in range(len(predicted_survival)):\n\tif predicted_survival[item] >= 0.5:\n\t\tpredicted_survival_clean.append(1)\n\telse:\n\t\tpredicted_survival_clean.append(0)\nprint(predicted_survival_clean)\n\n\nmy_submission = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predicted_survival_clean})\n\nmy_submission.to_csv('my_submission.csv', index=False)\nprint(my_submission)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e451238542aab9b4cb6fa5bb86253c8b5661db8"
      },
      "cell_type": "code",
      "source": "train.sample(15)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d604d216dab080f41fa462433f627bddbcd34616"
      },
      "cell_type": "code",
      "source": "train.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7d974b78bf25655f5334860cfb7abe9c7e1f679a",
        "_kg_hide-output": false,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "train.Embarked.unique()\n# train.Embarked.fillna(\"S\", inplace=True)\n# train.Embarked.unique()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9b8aa5336d4a10368dd4ae64ff2ff277298a4add"
      },
      "cell_type": "code",
      "source": "train.Parch.unique()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf1a7ec1a798d2be423dda6808f10137f96249c5"
      },
      "cell_type": "code",
      "source": "train.Parch.tail",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# train.describe()\ntrain.info()\n# train.hist(bins = 25, figsize=(20,15))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7170a5cda0ce4dddf9bbf0f464e6cb4759a3e8a6"
      },
      "cell_type": "code",
      "source": "test.Fare",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a493c6e6418ecc3fe3c527fda3a9c9eb350762b4"
      },
      "cell_type": "code",
      "source": "train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96cccfe2f313e0a79c038472fd30cdf9060f590d"
      },
      "cell_type": "code",
      "source": "train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4fde1976cf1ba4a0d35b4ec70425cd6a708ea58b"
      },
      "cell_type": "code",
      "source": "train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "0782fe6c040727545ce746a677d42ce220438ddd"
      },
      "cell_type": "code",
      "source": "corr_matrix = train.corr()\ncorr_matrix[\"Survived\"].sort_values(ascending=False)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f10f9409c1bbb04edd00fc91ad46c5115de3df45"
      },
      "cell_type": "code",
      "source": "corr_matrix = train.corr()\ncorr_matrix[\"\"].sort_values(ascending=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "62acb0812f4542d7d9d45616aef1ed688a0d4992"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n        {},\n# \t\t{'n_estimators': [3,10,30,150,200,250,275,300,325,3000],'max_depth': [1,2,4,5,6,8],},\n\t\t# {'bootstrap':[False],'n_estimators':[3,10],'max_features':[2,3,4]},\n\t]\nmy_Model = RandomForestRegressor()\n\ngrid_search = GridSearchCV(my_Model, param_grid, cv=5, scoring='neg_mean_squared_error')\ngrid_search.fit(train_X, train_y)\nprint(\"The best parameters for RandomForestRegressor are \",grid_search.best_params_)\n\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n\tprint(np.sqrt(-mean_score), params)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f1335f7993f487fa83df3e821ac5313333260a67"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n\t\t{'n_estimators': [3,10,20,30,50,60,90,100,150,200,300,500], 'max_depth': [2,6,8,10,12,16,20],},\n    # {'bootstrap':[False],'n_estimators':[3,10],'max_features':[2,3,4]},\n        \n        \n\t]\nmy_Model = RandomForestRegressor()\ngrid_search = GridSearchCV(my_Model, param_grid, cv=5, scoring='neg_mean_squared_error')\ngrid_search.fit(train_X, train_y)\nprint(\"The best parameters for RandomForestRegressor are \",grid_search.best_params_)\n\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n\tprint(1 - np.sqrt(-mean_score), params)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}